<!DOCTYPE HTML>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0RT4BLJBR8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0RT4BLJBR8');
</script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta name="google-site-verification" content="XXjK99sZKdpFN8kxwbglvDK8Gbhanfx-QfZGGG_TU1M" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

  <title>Akshay Bhatia</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Akshay Bhatia</name>
                
              </p>
              <p>Currently working as a Data Scientist at <a href="https://www.dell.com/en-us" target="_blank">Dell Technologies</a> and recently graduated(May '23') with a Master's in <a href="https://eecs.ucmerced.edu/" target="_blank">Electrical Engineering and Computer Science(EECS)</a> from <a href="https://www.ucmerced.edu/" target="_blank">University of California, Merced</a> where I worked with Professor <a href="https://faculty.ucmerced.edu/snewsam/" target="_blank">Shawn Newsam</a> in the <a href="http://vision.ucmerced.edu/" target="_blank">Computer Vision Lab</a>. In Summer '22, I interned at <a href="https://www.dell.com/en-us" target="_blank">Dell Technologies</a> in the data science team.</p>
                
                <p>
                Previously, I worked as a Research Scientist at <a href="https://knorex.com" target="_blank">Knorex Pte. Ltd.</a> in the Research & Prototyping team, supervised by <a href="https://yipingnus.github.io/" target="_blank">Jin Yiping</a>, with a focus on applying natural language processing for automated universal advertising tasks such as <a href="https://www.knorex.com/blog/articles/contextual-targeting" target="_blank">Contextual Targeting for Advertising</a>, <a href="https://knorex.zendesk.com/hc/en-us/articles/360022194611-Ad-Standards-Policy-and-Quality-Control" target="_blank">Brand Safety & Fraud Detection</a>, and <a href="https://www.knorex.com/blog/articles/dynamic-creative-optimization-dco" target="_blank">Dynamic Creative Optimization</a>.
              </p>

              <p>              
               I obtained my Bachelor's Degree(B.Tech) in Electronics & Communication Engineering from <a href="http://www.jiit.ac.in/" target="_blank">Jaypee Institute of Information Technology, India</a> in 2018.
              </p>
              <p>Before starting my Master's, I worked at: </p>
        <ul>
                <li><a href="https://knorex.com" target="_blank">Knorex Pte. Ltd.</a>, Research Scientist I - NLP, April 2019 - July 2021 with <a href="https://yipingnus.github.io/" target="_blank">Jin Yiping</a> </li>
                <li><a href="https://campk12.com" target="_blank">CampK12</a>, Machine Learning Developer Intern, June 2018 - December 2018 with <a href="http://anshulbhagi.com/" target="_blank">Anshul Bhagi</a> </li>
                <li><a href="https://www.linkedin.com/company/spikeway/" target="_blank">Spikeway Technologies</a>, Machine Learning Intern, Summer 2017 with <a
                    href="https://in.linkedin.com/in/praveenkkmrr" target="_blank">Praveen Kumar</a> </li>
              </ul>
              <p style="text-align:center">
                <a href="mailto:abhatia8@ucmerced.edu">Email</a> &nbsp/&nbsp
                <a href="data/Akshay_Bhatia_CV.pdf" target="_blank">CV</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/akshay-bhatia-5283abab/" target="_blank">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/akshaybhatia10" target="_blank">Github</a> &nbsp/&nbsp
                <a href="https://paperswithcode.com/search?q=author%3AAkshay+Bhatia" target="_blank">Papers with Code</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Zcs5Bn4AAAAJ&hl=en" target="_blank">Google Scholar</a>
              </p>
            </td>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_circle.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/pic.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Interests</heading>

              <p>
                My interests broadly lie in the fields of Natural Language Processing, Machine Learning, and Computer Vision. More recently, I have been working at the intersection of Computer Vision and Natural Language Processing for visio-linguistic tasks such as Image Captioning and Visual Question Answering for Geospatial and Remote Sensing domain in a unsupervised/semi-supervised setting. 
              </p>
              <p> 
                Previously, my work focused on weakly-supervised <a href="https://www.aclweb.org/anthology/2021.naacl-srw.14/" target="_blank">text classification</a> and context aware and controlled <a href="https://doi.org/10.1017/S1351324921000474" target="_blank">text generation</a> algorithms for applications in the <a href="https://knorex.zendesk.com/hc/en-us/articles/4407119434137" target="_blank">Dynamic Creative Optimization</a> domain. 
              </p>
            </td>
          </tr>
        </tbody>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
              <heading>Education</heading>
            </td>
          </tr>
        </table>
    <table id="publications" width="100%" align="center" border="0" border-spacing="0" border-collapse="separate"
          cellspacing="0" cellpadding="20">

          <tr>
            <td width="25%" valign="top">
                  <img src='images/merced.png' width="120" height="120">
            </td>
            <td width="75%" valign="center">
              <a href="http://www.ucmerced.edu/" target="_blank">
                <papertitle>University of California Merced</papertitle>
              </a>, <em>Merced, CA, USA</em>
              <br>
              <strong>Master's of Science</strong>
              <br>
               Electrical Engineering and Computer Science(EECS)
              <br>
              <br>
              Aug. 2021 - May 2023(
              <br>
              <br>
              <abstract>
                Graduate Teaching Assistant for:
                <ul>
                  <li>CSE 005: Intro to Computer Applications, Spring 2022</li>
                  <li>CSE 120: Software Engineering, Fall 2021</li>
                  <li>CSE 031: Computer Organization, Fall 2021</li>
                </ul>
              </abstract>
              <br>
            </td>
          </tr> 
          <tr>
            <td width="25%" valign="top">
                  <img src='images/jiit.png' width="100" height="120" style="margin-left: 0.6em;">
            </td>
            <td width="75%" valign="center">
              <a href="http://www.jiit.ac.in/" target="_blank">
                <papertitle>Jaypee Institute of Information Technology</papertitle>
              </a>, <em>Noida, UP, India</em>
              <br>
              <strong>Bachelors of Technology</strong>
              <br>
               Electronics and Communication Engineering(ECE)
              <br>
              <strong>Thesis</strong><em>:     Real-time control of Zigbee for Smart Shopping System using RFID</em>
              <br>
              <br>
              July 2014 - June 2018
            </td>
          </tr> 
      </table>

      <br>
      <br>
      <br>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </table>

        <table id="publications" width="100%" align="center" border="0" border-spacing="0" border-collapse="separate"
          cellspacing="0" cellpadding="20">
          <!-- <tr bgcolor="#ffffd0"> -->
          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/naacl.png' width="150" height="90">
            </td>
            <td width="75%" valign="center">
              <a href="https://www.aclweb.org/anthology/2021.naacl-srw.14/" target="_blank">
                <papertitle>Seed Word Selection for Weakly-Supervised Text Classification with Unsupervised Error Estimation
                </papertitle>
              <br>
              <a href="https://yipingnus.github.io/" target="_blank">Jin Yiping</a>,
              <strong>Akshay Bhatia</strong>,
              <a href="http://pioneer.netserv.chula.ac.th/~wdittaya/" target="_blank">Dittaya Wanvarie</a>
              <br>
              <font color="red"><i><a href="https://naacl2021-srw.github.io/accepted" target="_blank">NAACL SRW 2021</a></font></i>
              <br>
              <a href="https://arxiv.org/abs/2104.09765" target="_blank">arXiv</a> / <a href="https://www.aclweb.org/anthology/2021.naacl-srw.14.pdf" target="_blank">Paper</a> / <a href="https://github.com/YipingNUS/OptimSeed" target="_blank">Code</a>

              <br>
              <p align="justify">
                <abstract>
                  Weakly-supervised text classification aims to induce text classifiers from only a few user provided seed words. The vast majority of previous work assumes high-quality seed words are given. However, the expert-annotated seed words are sometimes non-trivial to come up with. Furthermore, in the weakly-supervised learning setting, we do not have any labeled document to measure the seed words’ efficacy, making the seed word selection process “a walk in the dark”. In this work, we remove the need for expert-curated seed words by first mining (noisy) candidate seed words associated with the category names. We then train interim models with individual candidate seed words. Lastly, we estimate the interim models’ error rate in an unsupervised manner. The seed words that yield the lowest estimated error rates are added to the final seed word set. A comprehensive evaluation of six binary classification tasks on four popular datasets demonstrates that the proposed method outperforms a baseline using only category name seed words and obtained comparable performance as a counterpart using expert-annotated seed words.
              </abstract>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/slo_gen.png' width="150" height="90">
            </td>
            <td width="75%" valign="center">
                <a href="https://doi.org/10.1017/S1351324921000474" target="_blank">
                <papertitle>Toward Improving Coherence and Diversity of Slogan Generation</papertitle>
            </a>  
              <br>
              <a href="https://yipingnus.github.io/" target="_blank">Jin Yiping</a>,
              <strong>Akshay Bhatia</strong>,
              <a href="http://pioneer.netserv.chula.ac.th/~wdittaya/" target="_blank">Dittaya Wanvarie</a>,
              <a href="https://www.linkedin.com/in/phultv" target="_blank">Phu T. V. Le</a>
              <br>              
              <i><a href="https://www.cambridge.org/core/journals/natural-language-engineering" target="_blank">Natural Language Engineering Journal, Cambridge University Press - 2021</a><font color="red"><strong></font></strong></em></i>
              <br>
              <a href="https://yipingnus.github.io/files/nle2021.pdf" target="_blank">Preprint</a> / <a href="https://github.com/YipingNUS/slogan-generation-dataset" target="_blank">Dataset</a>
              <br>
              <p align="justify">
                <abstract>
                  Previous work in slogan generation focused on utilising slogan skeletons mined from existing slogans. While some generated slogans can be catchy, they are often not coherent with the company’s focus or style across their marketing communications because the skeletons are mined from other companies’ slogans. We propose a sequence-to-sequence (seq2seq) Transformer model to generate slogans from a brief company description. A naïve seq2seq model fine-tuned for slogan generation is prone to introducing false information. We use company name delexicalisation and entity masking to alleviate this problem and improve the generated slogans’ quality and truthfulness. Furthermore, we apply conditional training based on the first words’ part-of-speech tag to generate syntactically diverse slogans. Our best model achieved a ROUGE-1/-2/-L  score of 35.58/18.47/33.32. Besides, automatic and human evaluations indicate that our method generates significantly more factual, diverse and catchy slogans than strong long short-term memory and Transformer seq2seq baselines.</abstract>
              </p>
            </td>
          </tr>
      </table>
      <br>
      <br>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
              <heading>Manuscripts</heading>
            </td>
          </tr>
      </table>

        <table id="publications" width="100%" align="center" border="0" border-spacing="0" border-collapse="separate"
          cellspacing="0" cellpadding="20">
          <!-- <tr bgcolor="#ffffd0"> -->
          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/sentinel.png' width="150" height="90">
            </td>
            <td width="75%" valign="center">
            <a href="data/sentinel.pdf" target="_blank">
                <papertitle>Sentinel: In-House Active Learning Platform
                </papertitle>
            </a>  
              <br>
              <strong>Akshay Bhatia</strong>,
              <a href="https://yipingnus.github.io/" target="_blank">Jin Yiping</a>,
              <a href="https://in.linkedin.com/in/vishakha-kadam-a6257a88" target="_blank">Vishakha Kadam</a>,
              <a href="https://vn.linkedin.com/in/huuthonguyen" target="_blank">Tho Nguyen</a>
              <br>
              Work done as part of Research Grant by <i><a href="https://www.enterprisesg.gov.sg/" target="_blank">Enterprise Singapore</a>, 2021</em></i>
              <br>
              <a href="data/sentinel.pdf" target="_blank">Manuscript</a>          
              <br>
              <p align="justify">
                <abstract>
          Modern applications require large datasets to train a classifier to achieve respectable results. But in practice, this incurs a significant cost since humans have to manually label data points. Active Learning(AL) is useful for reducing the amount of supervision needed for performing a task, by having the model select which data points should be labeled. We present <em>Sentinel</em>, an active learning platform capable of building text classifiers as well as annotating large amounts of text data. Our platform lets the user interact with the system and annotate and build text classifiers up to their requirements, thus requiring less human effort and time. More importantly, we implement a novel training strategy combining active learning with <em>tri-training</em> that performs better than <em>random</em>, <em>uncertainty</em>(entropy), and <em>expected gradient length</em>(EGL) sampling on 2 benchmark datasets. Through a series of experiments, we evaluate our platform, Sentinel, on various text classification benchmark datasets and a corpus of Real-Time Bidding (RTB) requests essential to the task of Brand Safety at Knorex. Our results demonstrate the effectiveness of our framework and provides for a computationally efficient sampling method.
              </abstract>
              </p>
            </td>
          </tr>
      </table>
      <br>
      <br>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
              <heading>Work Experience</heading>
            </td>
          </tr>
        </table>

        <table id="experience" width="100%" align="center" border="0" border-spacing="0" border-collapse="separate"
          cellspacing="0" cellpadding="20"><tbody>

          <tr>
            <td width="25%" valign="top">
                  <img src='images/dell.png' width="170", height="130">
            </td>
            <td swidth="75%" valign="center">
              <a href="https://www.dell.com/en-us" target="_blank">
                <papertitle>Dell Technologies</papertitle>
              </a>, <em>San Francisco, California, USA</em>
              <br>
              <strong>Data Scientist</strong>
              <br>
              July 2023 - Present
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
                  <img src='images/dell.png' width="170", height="130">
            </td>
            <td swidth="75%" valign="center">
              <a href="https://www.dell.com/en-us" target="_blank">
                <papertitle>Dell Technologies</papertitle>
              </a>, <em>Austin, Texas, USA</em>
              <br>
              <strong>Data Scientist Intern</strong>
              <br>
              May 2022 - August 2022
              <p align="justify">
                <ul>
                <li>Implemented the search and recommendation engine for Dell Knowledge Center Sales tool.</li>
                <li>Developed and deployed a zero-shot learning algorithm for an automated content tagging system.</li>
              </ul>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
                  <img src='images/merced.png' style="text-align: center;" width="110", height="100">
            </td>
            <td swidth="75%" valign="center">
              <a href="http://vision.ucmerced.edu/" target="_blank">
                <papertitle>Computer Vision Lab, UC Merced</papertitle>
              </a>, <em>Merced, USA</em>
              <br>
              <strong>Research Member</strong>
              <br>
              January 2022 - Present

              <p align="justify">
                <ul>
                <li>Working on devising semi-supervised learning algorithms for Image Captioning and Visual Question Answering for Geospatial and Remote Sensing Imagery data.</li>
              </ul>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
                  <img src='images/knorex.png' width="130", height="70">
            </td>
            <td swidth="75%" valign="center">
              <a href="https://knorex.com" target="_blank">
                <papertitle>Knorex</papertitle>
              </a>, <em>Pune, India</em>
              <br>
              <strong>Research Scientist I - NLP</strong>
              <br>
              April 2019 - July 2021

              <p align="justify">
                <ul>
                <li>Worked on training and evaluating text classification and text generation models for <a href="https://www.knorex.com/knorex-kairos" target="_blank">Knorex KAIROS's</a> Brand Safety and Contextual targeting offerings. Improved overall CTR on an average advertising campaign by 12%. Work published at <a href="https://www.aclweb.org/anthology/2021.naacl-srw.14/" target="_blank">NAACL SRW 2021.</a>.</li>
                <li>Responsible for the end-to-end development of <a href="data/sentinel.pdf" target="_blank">Sentinel: Intelligence-as-a-Service Platform for Content Moderation at Scale</a>, an Active Learning platform to build text classifiers without any labeled data - a research grant project supported by <a href="https://www.enterprisesg.gov.sg/" target="_blank">Enterprise Singapore</a>.</li>
                <li>Enhanced Transformer models with delexicalisation and entity masking for the task of automatically generating high quality advertising slogans for Dynamic creative optimization, surpassing previous benchmark results by 33%. Work published at <a href="https://arxiv.org/abs/2102.05924" target="_blank">NLE CUP 2021</a>.</li>
                <li>Supported several production ad-hoc features such as Keyword Extraction and Search Similarity for <a href="https://knorex.zendesk.com/hc/en-us/articles/360025021052-Overview-Of-XPO-Targeting-Capabilities" target="_blank">User-Defined Custom Segments</a> for Contextual Targeting.</li>
              </ul>
              </p>
            </td>
          </tr>   

          <tr>
            <td width="25%" valign="top">
                  <img src='images/campk12.png' width="130", height="70">
            </td>
            <td width="75%" valign="center">
              <a href="https://campk12.com" target="_blank">
                <papertitle>CampK12</papertitle>
              </a>, <em>Gurugram, India</em>
              <br>
              <strong>Machine Learning Developer Intern</strong>
              <br>
              June 2018 - December 2018

              <p align="justify">
              <ul>
                <li>Worked on LingoLens, a K12 language learning mobile app with real-time on-device object detection. Trained a custom YOLO model to detect 150 objects with an mAP of 67%.</li>
                <li>Subsequently optimized the on-device detection and classification inference speeds by 19% with only 6% performance degradation compared to SoTA methods such as RetinaNet and SSD.</li>
                <li>Co-designed and co-instructed CampK12's first <a href="https://campk12.com/course/ai-machine-learning-at-campk-12" target="_blank">Machine Learning & AI course</a>.</li>
                <li>Devised embedding and attribute-aware similarity models for the automatic question tagger system for the peer to peer question answering forum for the CampK12's <a href="https://bit.ly/3lGWJUu" target="_blank">Generation Blockchain 2018 Summit</a></li>
                <li>Explored the domain of Machine-assisted Assignment Grading and experimented with applying variations of neural language models and other embedding techniques to the task of Automatic Essay Scoring.</li>
              </ul>
              </p>
            </td>
          </tr> 

          <tr>
            <td width="25%" valign="top">
                  <img src='images/spikeway.png' width="130" height="60">
            </td>
            <td width="75%" valign="center">
              <a href="https://www.linkedin.com/company/spikeway/" target="_blank">
                <papertitle>Spikeway Technologies</papertitle>
              </a>, <em>Noida, India</em>
              <br>
              <strong>Machine Learning Intern</strong>
              <br>
              May 2017 - July 2017

              <p align="justify">
              <ul>
                <li>Led a 3 member team for the development and deployment of a ML-based <a href="https://github.com/akshaybhatia10/Book-Genre-Classification" target="_blank">Book Genre Classification</a> system to classify books into their genres, based entirely on its title, without knowledge of author and origin. Deployed the trained models with Kubernetes' containers and pods in production.</li>
                <li>Collaborated with the backend team on the prototype of a News Article Authorship Plagiarism Checker with a word embedding vector similarity approach.</li>
                <li>Worked directly with various e-commerce based clients on ways to integrate AI systems such as virtual assistants, query suggestions, recommendation engines etc. as web solutions for B2B businesses</li>
              </ul>
              </p>
            </td>
          </tr> 
     </table>   
     <br>
     <br>
     <br>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
              <heading>Teaching</heading>
            </td>
          </tr>
        </table>

                <table id="experience" width="100%" align="center" border="0" border-spacing="0" border-collapse="separate"
          cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td width="25%" valign="middle">
                  <img src='images/merced.png' width="120", height="120">
            </td>
            <td swidth="75%" valign="center">
              <a href="https://eng.ucmerced.edu/abet/courses/2022_10_CSE005-01/syllabus" target="_blank">
                <papertitle>CSE 005 - Intro Computer Applications</papertitle>
              </a>
              <br>
              Graduate Teaching Assistant
              <br>     
              <em>University of California Merced, Spring 2022</em>
              <br>
              <br>
              <br>
              <a href="" target="https://eng.ucmerced.edu/abet/courses/2021_30_CSE120-01/syllabus">
                <papertitle>CSE 120 - Software Engineering</papertitle>
              </a>
              <br>
              Graduate Teaching Assistant
              <br>     
              <em>University of California Merced, Fall 2021</em>
              <br>
              <br>
              <br>
              <a href="" target="https://eng.ucmerced.edu/abet/courses/2021_30_CSE031-01/syllabus">
                <papertitle>CSE 031 - Computer Organization</papertitle>
              </a>
              <br>
              Graduate Teaching Assistant
              <br>
              <em>University of California Merced, Fall 2021</em>
            </td>
          </tr>    
     </table>

     <br>
     <br>
     <br>  

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
              <heading>Relevant Projects</heading>
            </td>
          </tr>
        </table>

        <table id="publications" width="100%" align="center" border="0" border-spacing="0" border-collapse="separate"
          cellspacing="0" cellpadding="20">

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/map.png' width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="data/ms_akshay_final.pdf" target="_blank">
                <papertitle>Improving Cross-View Remote Sensing Image Retrieval with Images and Captions
                </papertitle>
            </a>
              <br>
              <em>Masters Project</em>
              <br>
              <a href="data/ms_akshay_final.pdf" target="_blank">Report</a>
              <br>
              <p align="justify">
                <abstract>
Cross-View Remote Sensing Image Retrieval or cross-view geo-localization is a fundamental research area in remote sensing image analysis. It is used to determine the position of a ground image query by correlating it with a database of geo-tagged satellite images and is often used for several applications such as disaster and damage assessment and monitoring road and terrain network understanding. But a common challenge for this task is the significant variation in view angles and time differences between the ground-level image and the corresponding aerial image. As a result, it is very difficult to capture global semantics and other relations between the two image pairs. Recent research has made remarkable strides in remote-sensing image retrieval benchmarks but conventional methods often overlook other modalities such as textual captions which describe the entities and other information present in ground-level images.
                  <br>
                  <br>
We propose a new approach to enhance the cross-view image retrieval results by utilizing both images and associated textual captions depicting geographic content that describe the contents of the ground-level image. Our framework ex- tracts geographic content and terrain features from the ground-level image and text caption. Finally, we curate a new dataset based on an existing geographic image captioning dataset, GeoRic. We do this by scraping overhead imagery for the corresponding ground-level images in the dataset using Google Static Maps API. We then demonstrate the effectiveness of our multi-modal approach on the newly created dataset by comparing it with existing unimodal and multi-modal deep learning-based image retrieval methods. Experimental results show that our approach outperforms the traditional image retrieval method and performs competitively with an image-text retrieval model in terms of retrieval accuracy. The incorporation of captions improves retrieval performance, especially in cases where the images have complex and varied visual content. In summary, this project proposes an approach to enhance the remote sensing image retrieval results by utilizing both images and captions. The proposed approach can capture the complex relationships between the images and captions and achieves superior performance compared to traditional unimodal image retrieval methods.
              </abstract>
              </p>
            </td>
          </tr>


          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/drone.png' width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="data/drone_fault_detection.pdf" target="_blank">
                <papertitle>Drone Fault Detection Based on ROS Topics
                </papertitle>
            </a>
              <br>
              <em>Course Project for EECS 283: Advanced Topics in Intelligent Systems with <a href="https://azinsh1988.github.io/AzinShamshirgaran/" target="_blank">Azin Shamshirgaran</a></em>
              <br>
              <a href="data/drone_fault_detection.pdf" target="_blank">Report</a>
              <br>
              <p align="justify">
                <abstract>
                  Explored the domain of external and internal fault detection systems for autonomous UAVs and drones. Main contributions included gathering and labeling of sensory data using a Parrot Bebop 2 drone and experimenting with variations of ordering techniques to enhance CNN models for 1D drone sensory data.
                  <br>
                  <br>
                  Improved vanilla CNNs using upsampled ordering for sensory data with inclusion of novel features, outperforming classical machine learning and existing heuristics' based algorithms with an AUC-ROC score of 94.3%.
              </abstract>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='https://raw.githubusercontent.com/akshaybhatia10/RoadNetworkExtraction-MoveHack/master/assets/n.png' width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="https://github.com/akshaybhatia10/RoadNetworkExtraction-MoveHack" target="_blank">
                <papertitle>Road Network Extraction using Satellite Imagery
                </papertitle>
            </a>
              <br>
              <em>Submission for MoveHack Global Mobility Hackathon 2018</em>
              <br>
              <a href="https://github.com/akshaybhatia10/RoadNetworkExtraction-MoveHack" target="_blank">Github</a> / 
              <a href="https://www.youtube.com/watch?v=iX5_mabCocY" target="_blank">Demo video</a>
              <br>
              <p align="justify">
                <abstract>
                  The project involved training and deploying a road segmentation and extraction system using high-resolution satellite imagery for reliable and low-cost terrain monitoring and infrastructure quality assessment.
                  <br>
                  <br>
                  Optimized the trained model for real-time applications with final inference speed of only 0.28 seconds on Tesla K80 GPU achieving a mask accuracy of 95% and a dice score of 65% on the validation set.
              </abstract>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/lingolens.png' width="140" height="100">
            </td>
            <td width="75%" valign="center">
            <a href="https://akshaybhatia10.github.io/lingolens.api/api-docs/" target="_blank">
                <papertitle>LingoLens
                </papertitle>
            </a>
              <br>
              <em>@<a href="https://campk12.com/" target="_blank">CampK12</a> with <a href="http://anshulbhagi.com/" target="_blank">Anshul Bhagi</a></em>
              <br>
              <a href="https://docs.google.com/presentation/d/1YmEspV94UykyZ23EJGJCXShHCSvlcj6lr3NkuRVEcyQ/edit?usp=sharing" target="_blank">Slides</a> / 
              <a href="https://akshaybhatia10.github.io/lingolens.api/api-docs/" target="_blank">API Docs</a>
              <br>
              <p align="justify">
                <abstract>
                  A multilingual language learning app for K12 students providing translations and transliterations for indoor and outdoor objects in over 20 languages.
                  <br>
                  <br>
                  We implemented a real-time object detection and on-device scene classification model Trained a custom YOLO model to detect ∼150 objects with an mAP of 67% improving the on-device detection and classification inference speeds by 19% with only 6% performance degradation compared to SoTA methods such as RetinaNet and SSD.
              </abstract>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src="images/book.png" width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="https://book-genre-classification.herokuapp.com/" target="_blank">
                <papertitle>Book Genre Classification
                </papertitle>
            </a>
              <br>
              <em>@<a href="http://www.spikewaysolutions.com/" target="_blank">Spikeway Technologies</a> with <a href="https://in.linkedin.com/in/praveenkkmrr" target="_blank">Praveen Kumar</a></em>
              <br>
              <a href="https://github.com/akshaybhatia10/Book-Genre-Classification" target="_blank">Github</a> /
              <a href="https://book-genre-classification.herokuapp.com/" target="_blank">Demo</a> 
              <br>
              <p align="justify">
                <abstract>
                  In this project, I led a 3 member team in the development of an ML-based system to classify books into their genres, based entirely on their title, without prior knowledge or context of author and origin.
                  <br>
                  <br>
                  I was responsible for the architecture, training, and deployment of the model. We improved the TFIDF and LR baselines by training a LSTM using pre-trained word2vec embeddings.
              </abstract>
              </p>
            </td>
          </tr>


          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src="images/cv.png" width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="https://github.com/akshaybhatia10/ComputerVision-Projects" target="_blank">
                <papertitle>Computer Vision Projects
                </papertitle>
            </a>
              <br>
              <em>Just for Fun</em>
              <br>
              <a href="https://github.com/akshaybhatia10/ComputerVision-Projects" target="_blank">Github</a>
              <br>
              <p align="justify">
                <abstract>
                  Open-source implementations for various computer vision tasks such as Template matching, Object Tracking, Face Swapper, Live Sketch, etc, using OpenCV.
                  <br>
                  <br>
                  100+ stars,  90+ forks.
              </abstract>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%" valign="top">
              <img id="paper_img" src='images/tc.png' width="140" height="100">
            </td>
            <td width="75%" valign="center">
              <a href="http://akshaybhatia10.herokuapp.com/" target="_blank">
                <papertitle>TravelCamp
                </papertitle>
            </a>
              <br>
              <em>Submission for IMAD 2016</em>
              <br>
              <a href="https://github.com/akshaybhatia10/imad-2016-app-heroku" target="_blank">Github</a> / 
              <a href="http://akshaybhatia10.herokuapp.com/" target="_blank">Demo</a>
              <br>
              <p align="justify">
                <abstract>
                  This project involved developing a social blog/profile web app where users can interact with each other. Other features including personal feed, posts, comments, signing, and logging in.
                  <br>
                  <br>
                  The web app follows RESTful approach for CRUD operations and was deployed using Heroku. Backend frameworks used: NodeJS, ExpressJS, MongoDB, PassportJS
                  
              </abstract>
              </p>
            </td>
          </tr>
      </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="1">
                  <a href="https://github.com/akshaybhatia10/" >More projects...</a>
                </font>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  <a href="https://jonbarron.info/" >Website template credits go to Jon Barron.</a>
                </font>
              </p>
            </td>
          </tr>
        </table>
<a href="https://info.flagcounter.com/KVYG"><img src="https://s04.flagcounter.com/count2/KVYG/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_15/viewers_0/labels_0/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
</body>

</html>
